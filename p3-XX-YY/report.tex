\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc} % sempre salve seus arquivos como UTF8
\usepackage[T1]{fontenc}
\usepackage[english]{babel}

\usepackage[left=2.5cm,right=2cm,top=2cm,bottom=2.5cm]{geometry}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}

\usepackage{graphicx}
\usepackage{algorithm}
\usepackage{color}
\usepackage[noend]{algpseudocode}
\usepackage{mathtools}
\usepackage{subfig}
\usepackage{diagbox}

% load times font
\usepackage{mathptmx}
\usepackage[scaled=.90]{helvet}
\usepackage{courier}

% comandos
\newcommand{\mdc}[1]{\mathrm{mdc}(#1)}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}

% Foot without marker
\newcommand\blfootnote[1]{%
	\begingroup
	\renewcommand\thefootnote{}\footnote{#1}%
	\addtocounter{footnote}{-1}%
	\endgroup
}

\title{MO446 -- Introduction to Computer Vision  \\ Project 3}
\author{Breno Leite  \\ Guilherme Leite}
\date{05/10/2017}

\begin{document}

\maketitle
\blfootnote{\textit{\textbf{Important note:} The borders seen in the figures are not part of the image, they are figurative information about the starting and ending points of the image. Moreover, all the image scales in this report were changed in order to make the text more readable.}} \\

%% ---------------- Starts here --------------------------------

\textbf{\LARGE Input Images}\\

Throughout this project some images are used as input to test the algorithms. Figure \ref{fig:p1-1-0} was used as input for the pyramids exercises \textbf{2.1, 2.2, 2.3} and \textbf{3.1}, its dimensions are 400x300 and it is a colored image. \\

\begin{table}[!h]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		& \multicolumn{3}{c|}{\textbf{Time (seconds)}} \\ \hline
		\backslashbox{\textbf{Convolution}}{\textbf{Kernel Size}}    & \textbf{3x3}         & \textbf{7x7}          & \textbf{15x15}      \\ \hline
		\textbf{Implemented}  & 4.481      & 4.535      & 5.083     \\ \hline
		\textbf{OpenCV} & 0.001      & 0.004       & 0.010     \\ \hline
	\end{tabular}
	\caption{Comparison between our implementation and OpenCV convolution time.}
	\label{table:convolution-opencv}
\end{table}

\textbf{\LARGE Question 3 - Keypoint Selection} \\

%The keypoint selection method chosen initially was the OpenCV implementation of the Harris selector, simply because it is a simpler and faster method to retrieve such points, but due to the fact that the threshold must be applied after retrieving all the points instead of cutting out the points on the fly, the execution of harris became slower than a SIFT run.
%sift vs harris
%qual é melhor? sift
%porque mais pontos

%faz tabela
%qual é melhor agora?
%depende, tradeoff de pontos(pontos desnecessários) de e tempo

The keypoint selectors explored in this project were Harris and SIFT selector, the most noticeable difference between them is the amount of keypoints extracted, the SIFT algorithm extracts way more keypoints than Harris, as seen in Figure \ref{fig:keypointSelection}.

\begin{figure}[!h]
	\centering
	\subfloat[Using Harris. (\textbf{p3-3-1})]{
		{
			\setlength{\fboxsep}{1pt}
			\setlength{\fboxrule}{1pt}
			\fbox{\includegraphics[scale=0.25]{output/p3-3-0}}
		}
		\label{fig:keypointSelectionHarris}
	}
	\quad
	\subfloat[Using SIFT. (\textbf{p3-3-0})]{
		{
			\setlength{\fboxsep}{1pt}
			\setlength{\fboxrule}{1pt}
			\fbox{\includegraphics[scale=0.25]{output/p3-3-1}}
		}
		\label{fig:keypointSelectionSift}
	}
	\caption{Difference between the keypoint selection methods.}
	\label{fig:keypointSelection}
\end{figure}

\begin{table}[!h]
	\centering
	\begin{tabular}{|c|c|c|c|}
		\hline
		& \multicolumn{3}{c|}{\textbf{Time (seconds)}} \\ \hline
		\backslashbox{\textbf{Number of executions}}{\textbf{Selection algorithm}}    & \textbf{Harris}         & \textbf{SIFT}          & \textbf{15x15}      \\ \hline
		\textbf{5 runs}  & 0.2714      & 0.0280      & 5.083     \\ \hline
		\textbf{OpenCV} & 0.001      & 0.004       & 0.010     \\ \hline
	\end{tabular}
	\caption{Comparison between our implementation and OpenCV convolution time.}
	\label{table:convolution-opencv}
\end{table}

\textbf{3.1 )} Exploring Fourier Space \\

To explore the Fourier space, we implemented two different functions. The first one is responsible to transform an image into vectors of magnitude and phase, while the other is responsible to reconstruct the image from the magnitude and phase vectors. The Figure \ref{fig:mag-phase} shows the magnitude and phase obtained transforming the Figure \ref{fig:p1-1-0} to the frequency domain. \\

\end{document}
